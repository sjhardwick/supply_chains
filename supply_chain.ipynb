{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "86fcd37a-b0e6-4ab2-9173-aa4e8ddc7642",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import beta\n",
    "\n",
    "# parameters and model set up\n",
    "\n",
    "sigma = 5               # elasticity of substitution between critical goods\n",
    "theta = 0.1             # between outside and critical good\n",
    "kappa = 0.5             # fixed entry cost\n",
    "z_h = {\"A\": 0.0, \"B\": 0.0}  # production subsidies for countries A and B\n",
    "e_h = {\"A\": 0.0, \"B\": 0.0}  # entry subsidy for countries A and B\n",
    "tau = 0.1                   # generic trade cost\n",
    "\n",
    "imtax_Fij = {\"A\": {\"A\": 0.00, \"B\": 0.00, \"C\": 0.00}, # import tariff on critical goods from i to j\n",
    "             \"B\": {\"A\": 0.00, \"B\": 0.00, \"C\": 0.00}}\n",
    "\n",
    "extax_Fij = {\"A\": {\"A\": 0.00, \"B\": 0.00}, # export tax on critical goods from i to j\n",
    "             \"B\": {\"A\": 0.00, \"B\": 0.00}}\n",
    "\n",
    "imtax_Ihi = {\"A\": {\"A\": 0.00, \"B\": 0.00}, # import tariff on inputs from h to i\n",
    "             \"B\": {\"A\": 0.00, \"B\": 0.00}}\n",
    "\n",
    "extax_Ihi = {\"A\": {\"A\": 0.00, \"B\": 0.00}, # export tax on inputs from h to i\n",
    "             \"B\": {\"A\": 0.00, \"B\": 0.00}}\n",
    "\n",
    "alpha_c = {\"A\": 6, \"B\": 19}  # alpha for country risk, e.g. 6 (~86%), 9 (90%), 19 (95%), 99 (99%)\n",
    "beta_c = {\"A\": 1, \"B\": 1}     # beta parameter (fix to 1)\n",
    "alpha_i = 19                  # alpha parameter for idiosyncratic risk\n",
    "beta_i = 1\n",
    "\n",
    "cvar_alpha = 0.95  # confidence level for CVaR\n",
    "\n",
    "np.random.seed(42) # random number seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "81760d54-77b0-4c38-9aed-9ff88b25b823",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 18 iterations.\n",
      "Overall mean utility (A): 9.774\n",
      "Overall mean utility (B): 9.779\n",
      "Overall mean utility (C): 9.726\n",
      "Mean CVaR (at α = 0.95) (A): 7.711\n",
      "Mean CVaR (at α = 0.95) (B): 7.634\n",
      "Mean CVaR (at α = 0.95) (C): 7.635\n"
     ]
    }
   ],
   "source": [
    "# run model\n",
    "# trade costs for critical goods from A to (A, B)\n",
    "t_Fij = {\n",
    "    i: {\n",
    "        j: 1 if i == j else 1 + imtax_Fij.get(i, {}).get(j, 0) + extax_Fij.get(i, {}).get(j, 0) + tau\n",
    "        for j in (\"A\", \"B\", \"C\") if j in imtax_Fij.get(i, {})\n",
    "    }\n",
    "    for i in (\"A\", \"B\", \"C\") if i in imtax_Fij\n",
    "}\n",
    "\n",
    "# trade costs for critical goods from A to (A, B)\n",
    "t_Ihi = {\n",
    "    h: {\n",
    "        i: 1 if h == i else 1 + imtax_Ihi.get(h, {}).get(i, 0) + extax_Ihi.get(h, {}).get(i, 0) + tau\n",
    "        for i in (\"A\", \"B\", \"C\") if i in imtax_Ihi.get(h, {})\n",
    "    }\n",
    "    for h in (\"A\", \"B\") if h in imtax_Ihi\n",
    "}\n",
    "\n",
    "# expected survival probability\n",
    "expected_phi_h = {\n",
    "    \"A\": (alpha_c[\"A\"]/(alpha_c[\"A\"] + beta_c[\"A\"]))*(alpha_i/(alpha_i + beta_i)),\n",
    "    \"B\": (alpha_c[\"B\"]/(alpha_c[\"B\"] + beta_c[\"B\"]))*(alpha_i/(alpha_i + beta_i)),\n",
    "}\n",
    "\n",
    "# calculate input prices\n",
    "p_Ih = {\n",
    "    \"A\": (sigma / (sigma - 1)) * (1 / expected_phi_h[\"A\"] - z_h[\"A\"]),\n",
    "    \"B\": (sigma / (sigma - 1)) * (1 / expected_phi_h[\"B\"] - z_h[\"B\"]),\n",
    "}\n",
    "\n",
    "# calculate price of final goods (p_Fi) = input price index (bar_P_Ii)\n",
    "p_Fi = {i: np.sum([(p_Ih[h] * t_Ihi[h][i]) ** (1 - sigma) for h in (\"A\", \"B\")]) ** (1 / (1 - sigma)) for i in (\"A\", \"B\")}\n",
    "\n",
    "# calculate price index for final goods consumed in country j\n",
    "bar_P_Fj = {j: np.sum([(p_Fi[i] * t_Fij[i][j]) ** (1 - sigma) for i in (\"A\", \"B\")]) ** (1 / (1 - sigma)) for j in (\"A\", \"B\", \"C\")}\n",
    "\n",
    "# expected demand for final goods\n",
    "expected_x_Fij = {\n",
    "    i: {j: (p_Fi[i] * t_Fij[i][j]) ** (-sigma) * bar_P_Fj[j] ** ((sigma * (1 - theta) - 1) / (1 - theta)) for j in (\"A\", \"B\", \"C\")}\n",
    "    for i in (\"A\", \"B\")\n",
    "}\n",
    "\n",
    "# expected demand for inputs\n",
    "expected_X_Ihi = {\n",
    "    h: {\n",
    "        i: (p_Ih[h] * t_Ihi[h][i]) ** -sigma\n",
    "        * sum(\n",
    "            t_Fij[i][j] ** -sigma\n",
    "            * bar_P_Fj[j] ** ((sigma * (1 - theta) - 1) / (1 - theta))\n",
    "            for j in (\"A\", \"B\", \"C\")\n",
    "        )\n",
    "        for i in (\"A\", \"B\")\n",
    "    }\n",
    "    for h in (\"A\", \"B\")\n",
    "}\n",
    "\n",
    "# n_h (number of entrants) for each h\n",
    "n_h = {\n",
    "    h: sum(expected_X_Ihi[h][i] for i in (\"A\", \"B\"))\n",
    "    / ((sigma - 1) * (1 - e_h[h]) * kappa)\n",
    "    * ((1 / expected_phi_h[h]) - z_h[h])\n",
    "    for h in (\"A\", \"B\")\n",
    "}\n",
    "\n",
    "# expected survivors for each h\n",
    "ns_h = {\n",
    "    h: n_h[h] * expected_phi_h[h] for h in (\"A\", \"B\")\n",
    "    for h in (\"A\", \"B\")\n",
    "}\n",
    "\n",
    "# monte carlo setup\n",
    "num_simulations = 40000\n",
    "max_iterations = 1000\n",
    "min_iterations = 5 # min before checking convergence\n",
    "iteration = 0\n",
    "results = []\n",
    "cvar_results = []\n",
    "tolerance = 0.01  # relative error tolerance\n",
    "z_alpha = 1.96    # critical z-value for 95% confidence\n",
    "\n",
    "# run the loop until convergence or max iterations\n",
    "while iteration < max_iterations:\n",
    "    iteration += 1   \n",
    "    \n",
    "    # generate risk factors\n",
    "    D_h = {\n",
    "        h: 1 - beta.rvs(alpha_c[h], beta_c[h], size = num_simulations)\n",
    "        for h in (\"A\", \"B\")\n",
    "    }\n",
    "    fail_all_h = {\n",
    "        h: np.random.rand(num_simulations) < D_h[h]\n",
    "        for h in (\"A\", \"B\")\n",
    "    }\n",
    "    phi_h = {\n",
    "        h: np.where(fail_all_h[h], 0, beta.rvs(alpha_i, beta_i, size = num_simulations))\n",
    "        for h in (\"A\", \"B\")\n",
    "    }\n",
    "    \n",
    "    # compute rho_i directly for all samples\n",
    "    rho_i = {\n",
    "        i: (np.sum(\n",
    "            [\n",
    "                (\n",
    "                    ((phi_h[h] / expected_phi_h[h]) ** ((sigma - 1) / sigma))\n",
    "                    * (\n",
    "                        (1 / expected_phi_h[h] - z_h[h]) ** (1 - sigma)\n",
    "                    )\n",
    "                    * (t_Ihi[h][i] ** (1 - sigma))\n",
    "                )\n",
    "                for h in (\"A\", \"B\")\n",
    "            ],\n",
    "            axis = 0,\n",
    "        )\n",
    "        / np.sum(\n",
    "            [\n",
    "                (\n",
    "                    (1 / expected_phi_h[h] - z_h[h]) ** (1 - sigma)\n",
    "                    * (t_Ihi[h][i] ** (1 - sigma))\n",
    "                )\n",
    "                for h in [\"A\", \"B\"]\n",
    "            ],\n",
    "            axis = 0,\n",
    "        )) ** (sigma / (sigma - 1))\n",
    "        for i in [\"A\", \"B\"]\n",
    "    }\n",
    "    \n",
    "    # tariff revenue\n",
    "    tariff_revenue = {\n",
    "        j: sum(\n",
    "            imtax_Fij.get(i, {}).get(j, 0) * rho_i.get(i, {}) * expected_x_Fij.get(i, {}).get(j, 0)\n",
    "            for i in (\"A\", \"B\") if i != j\n",
    "        ) + (sum(\n",
    "            imtax_Ihi.get(i, {}).get(j, 0) * phi_h[i] / expected_phi_h[i] * expected_X_Ihi.get(i, {}).get(j, 0)\n",
    "            for i in (\"A\", \"B\") if i != j\n",
    "        ) if j in (\"A\", \"B\") else 0)\n",
    "        + (sum(\n",
    "            extax_Fij.get(j, {}).get(i, 0) * rho_i.get(j, {}) * expected_x_Fij.get(j, {}).get(i, 0)\n",
    "            for i in (\"A\", \"B\") if j != i\n",
    "        ) if j in (\"A\", \"B\") else 0)\n",
    "        + (sum(\n",
    "            extax_Ihi.get(j, {}).get(i, 0) * phi_h[j] / expected_phi_h[j] * expected_X_Ihi.get(j, {}).get(i, 0)\n",
    "            for i in (\"A\", \"B\") if j != i\n",
    "        ) if j in (\"A\", \"B\") else 0)\n",
    "        for j in (\"A\", \"B\", \"C\")\n",
    "    }\n",
    "    \n",
    "    # production/entry subsidy cost\n",
    "    subsidy_cost = {\n",
    "        h: phi_h[h] * n_h[h] * e_h[h] + z_h[h] * sum(\n",
    "            phi_h[h] / expected_phi_h[h] * expected_X_Ihi[h][i] for i in (\"A\", \"B\")\n",
    "        )\n",
    "        for h in (\"A\", \"B\")\n",
    "    }\n",
    "    \n",
    "    # outside good consumption\n",
    "    x_0j = {\n",
    "        j: 1\n",
    "        + tariff_revenue.get(j, 0)\n",
    "        - subsidy_cost.get(j, 0)\n",
    "        - bar_P_Fj.get(j, 0) ** (-theta / (1 - theta))\n",
    "        for j in (\"A\", \"B\", \"C\")\n",
    "    }\n",
    "    \n",
    "    # compute utility U_j\n",
    "    sum_term = {\n",
    "        j: \n",
    "        (((rho_i[\"A\"] * expected_x_Fij[\"A\"][j]) ** ((sigma - 1) / sigma) + \n",
    "          (rho_i[\"B\"] * expected_x_Fij[\"B\"][j]) ** ((sigma - 1) / sigma)))\n",
    "        for j in (\"A\", \"B\", \"C\")\n",
    "    }\n",
    "    \n",
    "    U_j = {\n",
    "        j: x_0j.get(j, 0) +\n",
    "           (1 / theta) * (sum_term.get(j, 0) ** (theta * sigma / (sigma - 1)))\n",
    "        for j in (\"A\", \"B\", \"C\")\n",
    "    }\n",
    "    \n",
    "    # Calculate VaR as a dictionary\n",
    "    var_threshold = {\n",
    "        j: np.percentile(U_j[j], (1 - cvar_alpha) * 100) for j in U_j.keys()\n",
    "    }\n",
    "    \n",
    "    # Calculate CVaR as a dictionary\n",
    "    cvar = {\n",
    "        j: np.mean(U_j[j][U_j[j] <= var_threshold[j]]) for j in U_j.keys()\n",
    "    }\n",
    "    \n",
    "    # append results\n",
    "    cvar_results.append(cvar)\n",
    "    results.append({j: np.mean(U_j[j]) for j in U_j.keys()})\n",
    "\n",
    "    # extract utility and CVaR results for country \"A\"\n",
    "    cvar_results_A = [cvar[\"A\"] for cvar in cvar_results]\n",
    "    results_A = [result[\"A\"] for result in results]\n",
    "    \n",
    "    # calculate standard errors for country \"A\"\n",
    "    cvar_sem_A = (\n",
    "        np.std(cvar_results_A, ddof=1) / np.sqrt(len(cvar_results_A))\n",
    "        if len(cvar_results_A) > 1\n",
    "        else 0  # Use 0 if variance can't be computed\n",
    "    )\n",
    "    mean_sem_A = (\n",
    "        np.std(results_A, ddof=1) / np.sqrt(len(results_A))\n",
    "        if len(results_A) > 1\n",
    "        else 0\n",
    "    )\n",
    "    \n",
    "    # Calculate confidence interval widths for country \"A\"\n",
    "    mean_ci_width_A = 2 * z_alpha * mean_sem_A\n",
    "    cvar_ci_width_A = 2 * z_alpha * cvar_sem_A\n",
    "    \n",
    "    # Check convergence for country \"A\"\n",
    "    mean_converged_A = (\n",
    "        len(results_A) > min_iterations\n",
    "        and (mean_ci_width_A / np.abs(np.mean(results_A))) < tolerance\n",
    "    )\n",
    "    cvar_converged_A = (\n",
    "        len(cvar_results_A) > min_iterations\n",
    "        and (cvar_ci_width_A / np.abs(np.mean(cvar_results_A))) < tolerance\n",
    "    )\n",
    "    \n",
    "    if mean_converged_A and cvar_converged_A:\n",
    "        print(f\"Converged after {iteration} iterations.\")\n",
    "        break\n",
    "else:\n",
    "    print(\"Reached maximum iterations without convergence.\")\n",
    "\n",
    "# Extract utility and CVaR results for countries A and B\n",
    "results_A = [result[\"A\"] for result in results]\n",
    "results_B = [result[\"B\"] for result in results]\n",
    "results_C = [result[\"C\"] for result in results]\n",
    "cvar_results_A = [cvar[\"A\"] for cvar in cvar_results]\n",
    "cvar_results_B = [cvar[\"B\"] for cvar in cvar_results]\n",
    "cvar_results_C = [cvar[\"C\"] for cvar in cvar_results]\n",
    "\n",
    "# Output final results\n",
    "print(f\"Overall mean utility (A): {np.mean(results_A):.3f}\")\n",
    "print(f\"Overall mean utility (B): {np.mean(results_B):.3f}\")\n",
    "print(f\"Overall mean utility (C): {np.mean(results_C):.3f}\")\n",
    "print(f\"Mean CVaR (at α = {cvar_alpha}) (A): {np.mean(cvar_results_A):.3f}\")\n",
    "print(f\"Mean CVaR (at α = {cvar_alpha}) (B): {np.mean(cvar_results_B):.3f}\")\n",
    "print(f\"Mean CVaR (at α = {cvar_alpha}) (C): {np.mean(cvar_results_C):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "4a79ad47-3228-4310-93af-112583e6044e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.285951162094995"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_Fi[\"A\"]\n",
    "\n",
    "# no export tax:\n",
    "# x_FAj: {'A': 0.44201067707802294, 'B': 0.27064018638783477, 'C': 0.33383414544989437}\n",
    "# x_IAi: {'A': 0.43170730834807347, 'B': 0.26745988543714244} sum = 0.699\n",
    "# x_IBi: {'A': 0.44830950794420404, 'B': 0.7204005813821303}\n",
    "# p_FA: 1.285951162094995\n",
    "\n",
    "# small export tax:\n",
    "# x_FAj: {'A': 0.449709988455304, 'B': 0.27749737415511666, 'C': 0.34097512537138275}\n",
    "# x_IAi: {'A': 0.4406581869614697, 'B': 0.22863682620709336} sum = 0.669\n",
    "# x_IBi: {'A': 0.45760461115242806, 'B': 0.736245094508023}\n",
    "# p_FA: 1.285951162094995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2ba5f1b0-457f-48d6-8462-e2c2391d8821",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved.\n"
     ]
    }
   ],
   "source": [
    "# tariff loop\n",
    "# run the top two cells first to retrieve parameters\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "tariff_sequence = np.arange(0, 0.55, 0.05)\n",
    "loop_results = []\n",
    "\n",
    "for i in tariff_sequence:\n",
    "\n",
    "    tariff_AB = i\n",
    "    \n",
    "    for j in tariff_sequence:\n",
    "\n",
    "        tariff_BA = j\n",
    "\n",
    "        # import tariff on inputs from h to i\n",
    "        imtax_Ihi = {\"A\": {\"A\": 0.00, \"B\": tariff_AB}, \n",
    "                     \"B\": {\"A\": tariff_BA, \"B\": 0.00}}\n",
    "\n",
    "        # trade costs for critical goods from A to (A, B)\n",
    "        t_Fij = {\n",
    "            i: {\n",
    "                j: 1 if i == j else 1 + imtax_Fij.get(i, {}).get(j, 0) + extax_Fij.get(i, {}).get(j, 0) + tau\n",
    "                for j in (\"A\", \"B\", \"C\") if j in imtax_Fij.get(i, {})\n",
    "            }\n",
    "            for i in (\"A\", \"B\", \"C\") if i in imtax_Fij\n",
    "        }\n",
    "        \n",
    "        # trade costs for critical goods from A to (A, B)\n",
    "        t_Ihi = {\n",
    "            h: {\n",
    "                i: 1 if h == i else 1 + imtax_Ihi.get(h, {}).get(i, 0) + extax_Ihi.get(h, {}).get(i, 0) + tau\n",
    "                for i in (\"A\", \"B\", \"C\") if i in imtax_Ihi.get(h, {})\n",
    "            }\n",
    "            for h in (\"A\", \"B\") if h in imtax_Ihi\n",
    "        }\n",
    "        \n",
    "        # calculate price of final goods (p_Fi) = input price index (bar_P_Ii)\n",
    "        p_Fi = {i: np.sum([(p_Ih[h] * t_Ihi[h][i]) ** (1 - sigma) for h in (\"A\", \"B\")]) ** (1 / (1 - sigma)) for i in (\"A\", \"B\")}\n",
    "        \n",
    "        # calculate price index for final goods consumed in country j\n",
    "        bar_P_Fj = {j: np.sum([(p_Fi[i] * t_Fij[i][j]) ** (1 - sigma) for i in (\"A\", \"B\")]) ** (1 / (1 - sigma)) for j in (\"A\", \"B\", \"C\")}\n",
    "        \n",
    "        # expected demand for final goods\n",
    "        expected_x_Fij = {\n",
    "            i: {j: (p_Fi[i] * t_Fij[i][j]) ** (-sigma) * bar_P_Fj[j] ** ((sigma * (1 - theta) - 1) / (1 - theta)) for j in (\"A\", \"B\", \"C\")}\n",
    "            for i in (\"A\", \"B\")\n",
    "        }\n",
    "        \n",
    "        # expected demand for inputs\n",
    "        expected_X_Ihi = {\n",
    "            h: {\n",
    "                i: (p_Ih[h] * t_Ihi[h][i]) ** -sigma\n",
    "                * sum(\n",
    "                    t_Fij[i][j] ** -sigma\n",
    "                    * bar_P_Fj[j] ** ((sigma * (1 - theta) - 1) / (1 - theta))\n",
    "                    for j in (\"A\", \"B\", \"C\")\n",
    "                )\n",
    "                for i in (\"A\", \"B\")\n",
    "            }\n",
    "            for h in (\"A\", \"B\")\n",
    "        }\n",
    "        \n",
    "        # n_h (number of entrants) for each h\n",
    "        n_h = {\n",
    "            h: sum(expected_X_Ihi[h][i] for i in (\"A\", \"B\"))\n",
    "            / ((sigma - 1) * (1 - e_h[h]) * kappa)\n",
    "            * ((1 / expected_phi_h[h]) - z_h[h])\n",
    "            for h in (\"A\", \"B\")\n",
    "        }\n",
    "        \n",
    "        # expected survivors for each h\n",
    "        ns_h = {\n",
    "            h: n_h[h] * expected_phi_h[h] for h in (\"A\", \"B\")\n",
    "            for h in (\"A\", \"B\")\n",
    "        }\n",
    "        \n",
    "        # monte carlo setup\n",
    "        iteration = 0\n",
    "        results = []\n",
    "        cvar_results = []\n",
    "        \n",
    "        # run the loop until convergence or max iterations\n",
    "        while iteration < max_iterations:\n",
    "            iteration += 1   \n",
    "            \n",
    "            # generate risk factors\n",
    "            D_h = {\n",
    "                h: 1 - beta.rvs(alpha_c[h], beta_c[h], size = num_simulations)\n",
    "                for h in (\"A\", \"B\")\n",
    "            }\n",
    "            fail_all_h = {\n",
    "                h: np.random.rand(num_simulations) < D_h[h]\n",
    "                for h in (\"A\", \"B\")\n",
    "            }\n",
    "            phi_h = {\n",
    "                h: np.where(fail_all_h[h], 0, beta.rvs(alpha_i, beta_i, size = num_simulations))\n",
    "                for h in (\"A\", \"B\")\n",
    "            }\n",
    "            \n",
    "            # compute rho_i directly for all samples\n",
    "            rho_i = {\n",
    "                i: (np.sum(\n",
    "                    [\n",
    "                        (\n",
    "                            ((phi_h[h] / expected_phi_h[h]) ** ((sigma - 1) / sigma))\n",
    "                            * (\n",
    "                                (1 / expected_phi_h[h] - z_h[h]) ** (1 - sigma)\n",
    "                            )\n",
    "                            * (t_Ihi[h][i] ** (1 - sigma))\n",
    "                        )\n",
    "                        for h in (\"A\", \"B\")\n",
    "                    ],\n",
    "                    axis = 0,\n",
    "                )\n",
    "                / np.sum(\n",
    "                    [\n",
    "                        (\n",
    "                            (1 / expected_phi_h[h] - z_h[h]) ** (1 - sigma)\n",
    "                            * (t_Ihi[h][i] ** (1 - sigma))\n",
    "                        )\n",
    "                        for h in [\"A\", \"B\"]\n",
    "                    ],\n",
    "                    axis = 0,\n",
    "                )) ** (sigma / (sigma - 1))\n",
    "                for i in [\"A\", \"B\"]\n",
    "            }\n",
    "\n",
    "            # tariff revenue\n",
    "            tariff_revenue = {\n",
    "                j: sum(\n",
    "                    imtax_Fij.get(i, {}).get(j, 0) * rho_i.get(i, {}) * expected_x_Fij.get(i, {}).get(j, 0)\n",
    "                    for i in (\"A\", \"B\") if i != j\n",
    "                ) + (sum(\n",
    "                    imtax_Ihi.get(i, {}).get(j, 0) * phi_h[i] / expected_phi_h[i] * expected_X_Ihi.get(i, {}).get(j, 0)\n",
    "                    for i in (\"A\", \"B\") if i != j\n",
    "                ) if j in (\"A\", \"B\") else 0)\n",
    "                + (sum(\n",
    "                    extax_Fij.get(j, {}).get(i, 0) * rho_i.get(j, {}) * expected_x_Fij.get(j, {}).get(i, 0)\n",
    "                    for i in (\"A\", \"B\") if j != i\n",
    "                ) if j in (\"A\", \"B\") else 0)\n",
    "                + (sum(\n",
    "                    extax_Ihi.get(j, {}).get(i, 0) * phi_h[j] / expected_phi_h[j] * expected_X_Ihi.get(j, {}).get(i, 0)\n",
    "                    for i in (\"A\", \"B\") if j != i\n",
    "                ) if j in (\"A\", \"B\") else 0)\n",
    "                for j in (\"A\", \"B\", \"C\")\n",
    "            }\n",
    "            \n",
    "            # production/entry subsidy cost\n",
    "            subsidy_cost = {\n",
    "                h: phi_h[h] * n_h[h] * e_h[h] + z_h[h] * sum(\n",
    "                    phi_h[h] / expected_phi_h[h] * expected_X_Ihi[h][i] for i in (\"A\", \"B\")\n",
    "                )\n",
    "                for h in (\"A\", \"B\")\n",
    "            }\n",
    "            \n",
    "            # outside good consumption\n",
    "            x_0j = {\n",
    "                j: 1\n",
    "                + tariff_revenue.get(j, 0)\n",
    "                - subsidy_cost.get(j, 0)\n",
    "                - bar_P_Fj.get(j, 0) ** (-theta / (1 - theta))\n",
    "                for j in (\"A\", \"B\", \"C\")\n",
    "            }\n",
    "            \n",
    "            # compute utility U_j\n",
    "            sum_term = {\n",
    "                j: \n",
    "                (((rho_i[\"A\"] * expected_x_Fij[\"A\"][j]) ** ((sigma - 1) / sigma) + \n",
    "                  (rho_i[\"B\"] * expected_x_Fij[\"B\"][j]) ** ((sigma - 1) / sigma)))\n",
    "                for j in (\"A\", \"B\", \"C\")\n",
    "            }\n",
    "            \n",
    "            U_j = {\n",
    "                j: x_0j.get(j, 0) +\n",
    "                   (1 / theta) * (sum_term.get(j, 0) ** (theta * sigma / (sigma - 1)))\n",
    "                for j in (\"A\", \"B\")\n",
    "            }\n",
    "            \n",
    "            # Calculate VaR as a dictionary\n",
    "            var_threshold = {\n",
    "                j: np.percentile(U_j[j], (1 - cvar_alpha) * 100) for j in U_j.keys()\n",
    "            }\n",
    "            \n",
    "            # Calculate CVaR as a dictionary\n",
    "            cvar = {\n",
    "                j: np.mean([u for u in U_j[j] if u <= var_threshold[j]]) for j in U_j.keys()\n",
    "            }\n",
    "            \n",
    "            # Append results\n",
    "            cvar_results.append(cvar)\n",
    "            results.append({j: np.mean(U_j[j]) for j in U_j.keys()})\n",
    "        \n",
    "            # Extract utility and CVaR results for country \"A\"\n",
    "            cvar_results_A = [cvar[\"A\"] for cvar in cvar_results]\n",
    "            results_A = [result[\"A\"] for result in results]\n",
    "            \n",
    "            # calculate standard errors for country \"A\"\n",
    "            cvar_sem_A = (\n",
    "                np.std(cvar_results_A, ddof=1) / np.sqrt(len(cvar_results_A))\n",
    "                if len(cvar_results_A) > 1\n",
    "                else 0  # Use 0 if variance can't be computed\n",
    "            )\n",
    "            mean_sem_A = (\n",
    "                np.std(results_A, ddof=1) / np.sqrt(len(results_A))\n",
    "                if len(results_A) > 1\n",
    "                else 0\n",
    "            )\n",
    "            \n",
    "            # calculate confidence interval widths for country A\n",
    "            mean_ci_width_A = 2 * z_alpha * mean_sem_A\n",
    "            cvar_ci_width_A = 2 * z_alpha * cvar_sem_A\n",
    "            \n",
    "            # check convergence for country A\n",
    "            mean_converged_A = (\n",
    "                len(results_A) > min_iterations\n",
    "                and (mean_ci_width_A / np.abs(np.mean(results_A))) < tolerance\n",
    "            )\n",
    "            cvar_converged_A = (\n",
    "                len(cvar_results_A) > min_iterations\n",
    "                and (cvar_ci_width_A / np.abs(np.mean(cvar_results_A))) < tolerance\n",
    "            )\n",
    "            \n",
    "            if mean_converged_A and cvar_converged_A:\n",
    "                # print(f\"Converged after {iteration} iterations.\")\n",
    "                break\n",
    "        else:\n",
    "            print(\"Reached maximum iterations without convergence.\")\n",
    "\n",
    "        # after the monte carlo loop\n",
    "        final_cvar = {k: np.mean([c[k] for c in cvar_results]) for k in cvar.keys()}\n",
    "        final_utility = {k: np.mean([r[k] for r in results]) for k in results[0].keys()}\n",
    "        \n",
    "        # append to loop_results\n",
    "        loop_results.append({\n",
    "            \"tariff_AB\": tariff_AB,\n",
    "            \"tariff_BA\": tariff_BA,\n",
    "            \"utility_A\": final_utility[\"A\"],\n",
    "            \"utility_B\": final_utility[\"B\"],\n",
    "            \"cvar_A\": final_cvar[\"A\"],\n",
    "            \"cvar_B\": final_cvar[\"B\"],\n",
    "            \"symmetric\": 1 if tariff_AB == tariff_BA else 0\n",
    "        })\n",
    "\n",
    "# save csv\n",
    "results_df = pd.DataFrame(loop_results)\n",
    "results_df.to_csv(\"output/tariff_loop_high_risk.csv\", index=False)\n",
    "\n",
    "print(\"Results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f28f4fb4-5d15-4b71-9e33-685fcbc23072",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 out of 3721 (0.27%)\n",
      "Processed 20 out of 3721 (0.54%)\n",
      "Processed 30 out of 3721 (0.81%)\n",
      "Processed 40 out of 3721 (1.07%)\n",
      "Processed 50 out of 3721 (1.34%)\n",
      "Processed 60 out of 3721 (1.61%)\n",
      "Processed 70 out of 3721 (1.88%)\n",
      "Processed 80 out of 3721 (2.15%)\n",
      "Processed 90 out of 3721 (2.42%)\n",
      "Processed 100 out of 3721 (2.69%)\n",
      "Processed 110 out of 3721 (2.96%)\n",
      "Processed 120 out of 3721 (3.22%)\n",
      "Processed 130 out of 3721 (3.49%)\n",
      "Processed 140 out of 3721 (3.76%)\n",
      "Processed 150 out of 3721 (4.03%)\n",
      "Processed 160 out of 3721 (4.30%)\n",
      "Processed 170 out of 3721 (4.57%)\n",
      "Processed 180 out of 3721 (4.84%)\n",
      "Processed 190 out of 3721 (5.11%)\n",
      "Processed 200 out of 3721 (5.37%)\n",
      "Processed 210 out of 3721 (5.64%)\n",
      "Processed 220 out of 3721 (5.91%)\n",
      "Processed 230 out of 3721 (6.18%)\n",
      "Processed 240 out of 3721 (6.45%)\n",
      "Processed 250 out of 3721 (6.72%)\n",
      "Processed 260 out of 3721 (6.99%)\n",
      "Processed 270 out of 3721 (7.26%)\n",
      "Processed 280 out of 3721 (7.52%)\n",
      "Processed 290 out of 3721 (7.79%)\n",
      "Processed 300 out of 3721 (8.06%)\n",
      "Processed 310 out of 3721 (8.33%)\n",
      "Processed 320 out of 3721 (8.60%)\n",
      "Processed 330 out of 3721 (8.87%)\n",
      "Processed 340 out of 3721 (9.14%)\n",
      "Processed 350 out of 3721 (9.41%)\n",
      "Processed 360 out of 3721 (9.67%)\n",
      "Processed 370 out of 3721 (9.94%)\n",
      "Processed 380 out of 3721 (10.21%)\n",
      "Processed 390 out of 3721 (10.48%)\n",
      "Processed 400 out of 3721 (10.75%)\n",
      "Processed 410 out of 3721 (11.02%)\n",
      "Processed 420 out of 3721 (11.29%)\n",
      "Processed 430 out of 3721 (11.56%)\n",
      "Processed 440 out of 3721 (11.82%)\n",
      "Processed 450 out of 3721 (12.09%)\n",
      "Processed 460 out of 3721 (12.36%)\n",
      "Processed 470 out of 3721 (12.63%)\n",
      "Processed 480 out of 3721 (12.90%)\n",
      "Processed 490 out of 3721 (13.17%)\n",
      "Processed 500 out of 3721 (13.44%)\n",
      "Processed 510 out of 3721 (13.71%)\n",
      "Processed 520 out of 3721 (13.97%)\n",
      "Processed 530 out of 3721 (14.24%)\n",
      "Processed 540 out of 3721 (14.51%)\n",
      "Processed 550 out of 3721 (14.78%)\n",
      "Processed 560 out of 3721 (15.05%)\n",
      "Processed 570 out of 3721 (15.32%)\n",
      "Processed 580 out of 3721 (15.59%)\n",
      "Processed 590 out of 3721 (15.86%)\n",
      "Processed 600 out of 3721 (16.12%)\n",
      "Processed 610 out of 3721 (16.39%)\n",
      "Processed 620 out of 3721 (16.66%)\n",
      "Processed 630 out of 3721 (16.93%)\n",
      "Processed 640 out of 3721 (17.20%)\n",
      "Processed 650 out of 3721 (17.47%)\n",
      "Processed 660 out of 3721 (17.74%)\n",
      "Processed 670 out of 3721 (18.01%)\n",
      "Processed 680 out of 3721 (18.27%)\n",
      "Processed 690 out of 3721 (18.54%)\n",
      "Processed 700 out of 3721 (18.81%)\n",
      "Processed 710 out of 3721 (19.08%)\n",
      "Processed 720 out of 3721 (19.35%)\n",
      "Processed 730 out of 3721 (19.62%)\n",
      "Processed 740 out of 3721 (19.89%)\n",
      "Processed 750 out of 3721 (20.16%)\n",
      "Processed 760 out of 3721 (20.42%)\n",
      "Processed 770 out of 3721 (20.69%)\n",
      "Processed 780 out of 3721 (20.96%)\n",
      "Processed 790 out of 3721 (21.23%)\n",
      "Processed 800 out of 3721 (21.50%)\n",
      "Processed 810 out of 3721 (21.77%)\n",
      "Processed 820 out of 3721 (22.04%)\n",
      "Processed 830 out of 3721 (22.31%)\n",
      "Processed 840 out of 3721 (22.57%)\n",
      "Processed 850 out of 3721 (22.84%)\n",
      "Processed 860 out of 3721 (23.11%)\n",
      "Processed 870 out of 3721 (23.38%)\n",
      "Processed 880 out of 3721 (23.65%)\n",
      "Processed 890 out of 3721 (23.92%)\n",
      "Processed 900 out of 3721 (24.19%)\n",
      "Processed 910 out of 3721 (24.46%)\n",
      "Processed 920 out of 3721 (24.72%)\n",
      "Processed 930 out of 3721 (24.99%)\n",
      "Processed 940 out of 3721 (25.26%)\n",
      "Processed 950 out of 3721 (25.53%)\n",
      "Processed 960 out of 3721 (25.80%)\n",
      "Processed 970 out of 3721 (26.07%)\n",
      "Processed 980 out of 3721 (26.34%)\n",
      "Processed 990 out of 3721 (26.61%)\n",
      "Processed 1000 out of 3721 (26.87%)\n",
      "Processed 1010 out of 3721 (27.14%)\n",
      "Processed 1020 out of 3721 (27.41%)\n",
      "Processed 1030 out of 3721 (27.68%)\n",
      "Processed 1040 out of 3721 (27.95%)\n",
      "Processed 1050 out of 3721 (28.22%)\n",
      "Processed 1060 out of 3721 (28.49%)\n",
      "Processed 1070 out of 3721 (28.76%)\n",
      "Processed 1080 out of 3721 (29.02%)\n",
      "Processed 1090 out of 3721 (29.29%)\n",
      "Processed 1100 out of 3721 (29.56%)\n",
      "Processed 1110 out of 3721 (29.83%)\n",
      "Processed 1120 out of 3721 (30.10%)\n",
      "Processed 1130 out of 3721 (30.37%)\n",
      "Processed 1140 out of 3721 (30.64%)\n",
      "Processed 1150 out of 3721 (30.91%)\n",
      "Processed 1160 out of 3721 (31.17%)\n",
      "Processed 1170 out of 3721 (31.44%)\n",
      "Processed 1180 out of 3721 (31.71%)\n",
      "Processed 1190 out of 3721 (31.98%)\n",
      "Processed 1200 out of 3721 (32.25%)\n",
      "Processed 1210 out of 3721 (32.52%)\n",
      "Processed 1220 out of 3721 (32.79%)\n",
      "Processed 1230 out of 3721 (33.06%)\n",
      "Processed 1240 out of 3721 (33.32%)\n",
      "Processed 1250 out of 3721 (33.59%)\n",
      "Processed 1260 out of 3721 (33.86%)\n",
      "Processed 1270 out of 3721 (34.13%)\n",
      "Processed 1280 out of 3721 (34.40%)\n",
      "Processed 1290 out of 3721 (34.67%)\n",
      "Processed 1300 out of 3721 (34.94%)\n",
      "Processed 1310 out of 3721 (35.21%)\n",
      "Processed 1320 out of 3721 (35.47%)\n",
      "Processed 1330 out of 3721 (35.74%)\n",
      "Processed 1340 out of 3721 (36.01%)\n",
      "Processed 1350 out of 3721 (36.28%)\n",
      "Processed 1360 out of 3721 (36.55%)\n",
      "Processed 1370 out of 3721 (36.82%)\n",
      "Processed 1380 out of 3721 (37.09%)\n",
      "Processed 1390 out of 3721 (37.36%)\n",
      "Processed 1400 out of 3721 (37.62%)\n",
      "Processed 1410 out of 3721 (37.89%)\n",
      "Processed 1420 out of 3721 (38.16%)\n",
      "Processed 1430 out of 3721 (38.43%)\n",
      "Processed 1440 out of 3721 (38.70%)\n",
      "Processed 1450 out of 3721 (38.97%)\n",
      "Processed 1460 out of 3721 (39.24%)\n",
      "Processed 1470 out of 3721 (39.51%)\n",
      "Processed 1480 out of 3721 (39.77%)\n",
      "Processed 1490 out of 3721 (40.04%)\n",
      "Processed 1500 out of 3721 (40.31%)\n",
      "Processed 1510 out of 3721 (40.58%)\n",
      "Processed 1520 out of 3721 (40.85%)\n",
      "Processed 1530 out of 3721 (41.12%)\n",
      "Processed 1540 out of 3721 (41.39%)\n",
      "Processed 1550 out of 3721 (41.66%)\n",
      "Processed 1560 out of 3721 (41.92%)\n",
      "Processed 1570 out of 3721 (42.19%)\n",
      "Processed 1580 out of 3721 (42.46%)\n",
      "Processed 1590 out of 3721 (42.73%)\n",
      "Processed 1600 out of 3721 (43.00%)\n",
      "Processed 1610 out of 3721 (43.27%)\n",
      "Processed 1620 out of 3721 (43.54%)\n",
      "Processed 1630 out of 3721 (43.81%)\n",
      "Processed 1640 out of 3721 (44.07%)\n",
      "Processed 1650 out of 3721 (44.34%)\n",
      "Processed 1660 out of 3721 (44.61%)\n",
      "Processed 1670 out of 3721 (44.88%)\n",
      "Processed 1680 out of 3721 (45.15%)\n",
      "Processed 1690 out of 3721 (45.42%)\n",
      "Processed 1700 out of 3721 (45.69%)\n",
      "Processed 1710 out of 3721 (45.96%)\n",
      "Processed 1720 out of 3721 (46.22%)\n",
      "Processed 1730 out of 3721 (46.49%)\n",
      "Processed 1740 out of 3721 (46.76%)\n",
      "Processed 1750 out of 3721 (47.03%)\n",
      "Processed 1760 out of 3721 (47.30%)\n",
      "Processed 1770 out of 3721 (47.57%)\n",
      "Processed 1780 out of 3721 (47.84%)\n",
      "Processed 1790 out of 3721 (48.11%)\n",
      "Processed 1800 out of 3721 (48.37%)\n",
      "Processed 1810 out of 3721 (48.64%)\n",
      "Processed 1820 out of 3721 (48.91%)\n",
      "Processed 1830 out of 3721 (49.18%)\n",
      "Processed 1840 out of 3721 (49.45%)\n",
      "Processed 1850 out of 3721 (49.72%)\n",
      "Processed 1860 out of 3721 (49.99%)\n",
      "Processed 1870 out of 3721 (50.26%)\n",
      "Processed 1880 out of 3721 (50.52%)\n",
      "Processed 1890 out of 3721 (50.79%)\n",
      "Processed 1900 out of 3721 (51.06%)\n",
      "Processed 1910 out of 3721 (51.33%)\n",
      "Processed 1920 out of 3721 (51.60%)\n",
      "Processed 1930 out of 3721 (51.87%)\n",
      "Processed 1940 out of 3721 (52.14%)\n",
      "Processed 1950 out of 3721 (52.41%)\n",
      "Processed 1960 out of 3721 (52.67%)\n",
      "Processed 1970 out of 3721 (52.94%)\n",
      "Processed 1980 out of 3721 (53.21%)\n",
      "Processed 1990 out of 3721 (53.48%)\n",
      "Processed 2000 out of 3721 (53.75%)\n",
      "Processed 2010 out of 3721 (54.02%)\n",
      "Processed 2020 out of 3721 (54.29%)\n",
      "Processed 2030 out of 3721 (54.56%)\n",
      "Processed 2040 out of 3721 (54.82%)\n",
      "Processed 2050 out of 3721 (55.09%)\n",
      "Processed 2060 out of 3721 (55.36%)\n",
      "Processed 2070 out of 3721 (55.63%)\n",
      "Processed 2080 out of 3721 (55.90%)\n",
      "Processed 2090 out of 3721 (56.17%)\n",
      "Processed 2100 out of 3721 (56.44%)\n",
      "Processed 2110 out of 3721 (56.71%)\n",
      "Processed 2120 out of 3721 (56.97%)\n",
      "Processed 2130 out of 3721 (57.24%)\n",
      "Processed 2140 out of 3721 (57.51%)\n",
      "Processed 2150 out of 3721 (57.78%)\n",
      "Processed 2160 out of 3721 (58.05%)\n",
      "Processed 2170 out of 3721 (58.32%)\n",
      "Processed 2180 out of 3721 (58.59%)\n",
      "Processed 2190 out of 3721 (58.86%)\n",
      "Processed 2200 out of 3721 (59.12%)\n",
      "Processed 2210 out of 3721 (59.39%)\n",
      "Processed 2220 out of 3721 (59.66%)\n",
      "Processed 2230 out of 3721 (59.93%)\n",
      "Processed 2240 out of 3721 (60.20%)\n",
      "Processed 2250 out of 3721 (60.47%)\n",
      "Processed 2260 out of 3721 (60.74%)\n",
      "Processed 2270 out of 3721 (61.01%)\n",
      "Processed 2280 out of 3721 (61.27%)\n",
      "Processed 2290 out of 3721 (61.54%)\n",
      "Processed 2300 out of 3721 (61.81%)\n",
      "Processed 2310 out of 3721 (62.08%)\n",
      "Processed 2320 out of 3721 (62.35%)\n",
      "Processed 2330 out of 3721 (62.62%)\n",
      "Processed 2340 out of 3721 (62.89%)\n",
      "Processed 2350 out of 3721 (63.16%)\n",
      "Processed 2360 out of 3721 (63.42%)\n",
      "Processed 2370 out of 3721 (63.69%)\n",
      "Processed 2380 out of 3721 (63.96%)\n",
      "Processed 2390 out of 3721 (64.23%)\n",
      "Processed 2400 out of 3721 (64.50%)\n",
      "Processed 2410 out of 3721 (64.77%)\n",
      "Processed 2420 out of 3721 (65.04%)\n",
      "Processed 2430 out of 3721 (65.31%)\n",
      "Processed 2440 out of 3721 (65.57%)\n",
      "Processed 2450 out of 3721 (65.84%)\n",
      "Processed 2460 out of 3721 (66.11%)\n",
      "Processed 2470 out of 3721 (66.38%)\n",
      "Processed 2480 out of 3721 (66.65%)\n",
      "Processed 2490 out of 3721 (66.92%)\n",
      "Processed 2500 out of 3721 (67.19%)\n",
      "Processed 2510 out of 3721 (67.45%)\n",
      "Processed 2520 out of 3721 (67.72%)\n",
      "Processed 2530 out of 3721 (67.99%)\n",
      "Processed 2540 out of 3721 (68.26%)\n",
      "Processed 2550 out of 3721 (68.53%)\n",
      "Processed 2560 out of 3721 (68.80%)\n",
      "Processed 2570 out of 3721 (69.07%)\n",
      "Processed 2580 out of 3721 (69.34%)\n",
      "Processed 2590 out of 3721 (69.60%)\n",
      "Processed 2600 out of 3721 (69.87%)\n",
      "Processed 2610 out of 3721 (70.14%)\n",
      "Processed 2620 out of 3721 (70.41%)\n",
      "Processed 2630 out of 3721 (70.68%)\n",
      "Processed 2640 out of 3721 (70.95%)\n",
      "Processed 2650 out of 3721 (71.22%)\n",
      "Processed 2660 out of 3721 (71.49%)\n",
      "Processed 2670 out of 3721 (71.75%)\n",
      "Processed 2680 out of 3721 (72.02%)\n",
      "Processed 2690 out of 3721 (72.29%)\n",
      "Processed 2700 out of 3721 (72.56%)\n",
      "Processed 2710 out of 3721 (72.83%)\n",
      "Processed 2720 out of 3721 (73.10%)\n",
      "Processed 2730 out of 3721 (73.37%)\n",
      "Processed 2740 out of 3721 (73.64%)\n",
      "Processed 2750 out of 3721 (73.90%)\n",
      "Processed 2760 out of 3721 (74.17%)\n",
      "Processed 2770 out of 3721 (74.44%)\n",
      "Processed 2780 out of 3721 (74.71%)\n",
      "Processed 2790 out of 3721 (74.98%)\n",
      "Processed 2800 out of 3721 (75.25%)\n",
      "Processed 2810 out of 3721 (75.52%)\n",
      "Processed 2820 out of 3721 (75.79%)\n",
      "Processed 2830 out of 3721 (76.05%)\n",
      "Processed 2840 out of 3721 (76.32%)\n",
      "Processed 2850 out of 3721 (76.59%)\n",
      "Processed 2860 out of 3721 (76.86%)\n",
      "Processed 2870 out of 3721 (77.13%)\n",
      "Processed 2880 out of 3721 (77.40%)\n",
      "Processed 2890 out of 3721 (77.67%)\n",
      "Processed 2900 out of 3721 (77.94%)\n",
      "Processed 2910 out of 3721 (78.20%)\n",
      "Processed 2920 out of 3721 (78.47%)\n",
      "Processed 2930 out of 3721 (78.74%)\n",
      "Processed 2940 out of 3721 (79.01%)\n",
      "Processed 2950 out of 3721 (79.28%)\n",
      "Processed 2960 out of 3721 (79.55%)\n",
      "Processed 2970 out of 3721 (79.82%)\n",
      "Processed 2980 out of 3721 (80.09%)\n",
      "Processed 2990 out of 3721 (80.35%)\n",
      "Processed 3000 out of 3721 (80.62%)\n",
      "Processed 3010 out of 3721 (80.89%)\n",
      "Processed 3020 out of 3721 (81.16%)\n",
      "Processed 3030 out of 3721 (81.43%)\n",
      "Processed 3040 out of 3721 (81.70%)\n",
      "Processed 3050 out of 3721 (81.97%)\n",
      "Processed 3060 out of 3721 (82.24%)\n",
      "Processed 3070 out of 3721 (82.50%)\n",
      "Processed 3080 out of 3721 (82.77%)\n",
      "Processed 3090 out of 3721 (83.04%)\n",
      "Processed 3100 out of 3721 (83.31%)\n",
      "Processed 3110 out of 3721 (83.58%)\n",
      "Processed 3120 out of 3721 (83.85%)\n",
      "Processed 3130 out of 3721 (84.12%)\n",
      "Processed 3140 out of 3721 (84.39%)\n",
      "Processed 3150 out of 3721 (84.65%)\n",
      "Processed 3160 out of 3721 (84.92%)\n",
      "Processed 3170 out of 3721 (85.19%)\n",
      "Processed 3180 out of 3721 (85.46%)\n",
      "Processed 3190 out of 3721 (85.73%)\n",
      "Processed 3200 out of 3721 (86.00%)\n",
      "Processed 3210 out of 3721 (86.27%)\n",
      "Processed 3220 out of 3721 (86.54%)\n",
      "Processed 3230 out of 3721 (86.80%)\n",
      "Processed 3240 out of 3721 (87.07%)\n",
      "Processed 3250 out of 3721 (87.34%)\n",
      "Processed 3260 out of 3721 (87.61%)\n",
      "Processed 3270 out of 3721 (87.88%)\n",
      "Processed 3280 out of 3721 (88.15%)\n",
      "Processed 3290 out of 3721 (88.42%)\n",
      "Processed 3300 out of 3721 (88.69%)\n",
      "Processed 3310 out of 3721 (88.95%)\n",
      "Processed 3320 out of 3721 (89.22%)\n",
      "Processed 3330 out of 3721 (89.49%)\n",
      "Processed 3340 out of 3721 (89.76%)\n",
      "Processed 3350 out of 3721 (90.03%)\n",
      "Processed 3360 out of 3721 (90.30%)\n",
      "Processed 3370 out of 3721 (90.57%)\n",
      "Processed 3380 out of 3721 (90.84%)\n",
      "Processed 3390 out of 3721 (91.10%)\n",
      "Processed 3400 out of 3721 (91.37%)\n",
      "Processed 3410 out of 3721 (91.64%)\n",
      "Processed 3420 out of 3721 (91.91%)\n",
      "Processed 3430 out of 3721 (92.18%)\n",
      "Processed 3440 out of 3721 (92.45%)\n",
      "Processed 3450 out of 3721 (92.72%)\n",
      "Processed 3460 out of 3721 (92.99%)\n",
      "Processed 3470 out of 3721 (93.25%)\n",
      "Processed 3480 out of 3721 (93.52%)\n",
      "Processed 3490 out of 3721 (93.79%)\n",
      "Processed 3500 out of 3721 (94.06%)\n",
      "Processed 3510 out of 3721 (94.33%)\n",
      "Processed 3520 out of 3721 (94.60%)\n",
      "Processed 3530 out of 3721 (94.87%)\n",
      "Processed 3540 out of 3721 (95.14%)\n",
      "Processed 3550 out of 3721 (95.40%)\n",
      "Processed 3560 out of 3721 (95.67%)\n",
      "Processed 3570 out of 3721 (95.94%)\n",
      "Processed 3580 out of 3721 (96.21%)\n",
      "Processed 3590 out of 3721 (96.48%)\n",
      "Processed 3600 out of 3721 (96.75%)\n",
      "Processed 3610 out of 3721 (97.02%)\n",
      "Processed 3620 out of 3721 (97.29%)\n",
      "Processed 3630 out of 3721 (97.55%)\n",
      "Processed 3640 out of 3721 (97.82%)\n",
      "Processed 3650 out of 3721 (98.09%)\n",
      "Processed 3660 out of 3721 (98.36%)\n",
      "Processed 3670 out of 3721 (98.63%)\n",
      "Processed 3680 out of 3721 (98.90%)\n",
      "Processed 3690 out of 3721 (99.17%)\n",
      "Processed 3700 out of 3721 (99.44%)\n",
      "Processed 3710 out of 3721 (99.70%)\n",
      "Processed 3720 out of 3721 (99.97%)\n",
      "Processed 3721 out of 3721 (100.00%)\n",
      "Results saved as export_tax_loop_asymmetric_risk.csv\n"
     ]
    }
   ],
   "source": [
    "# export tax loop\n",
    "# run the top two cells first to retrieve parameters\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "extax_sequence = np.arange(0, 3.05, 0.05)\n",
    "ex_loop_results = []\n",
    "\n",
    "# define the logging function\n",
    "def log_progress(current, total, interval=1):\n",
    "    \"\"\"Logs progress at a specified interval.\"\"\"\n",
    "    if current % interval == 0 or current == total:\n",
    "        print(f\"Processed {current} out of {total} ({(current / total) * 100:.2f}%)\")\n",
    "\n",
    "# count total iterations for logging\n",
    "total_iterations = len(extax_sequence) ** 2\n",
    "current_iteration = 0\n",
    "\n",
    "for i in extax_sequence:\n",
    "\n",
    "    extax_AB = i\n",
    "    \n",
    "    for j in extax_sequence:\n",
    "\n",
    "        extax_BA = j\n",
    "\n",
    "        # export tax on inputs from h to i\n",
    "        extax_Ihi = {\"A\": {\"A\": 0.00, \"B\": extax_AB},\n",
    "                     \"B\": {\"A\": extax_BA, \"B\": 0.00}}\n",
    "\n",
    "        # trade costs for critical goods from A to (A, B)\n",
    "        t_Fij = {\n",
    "            i: {\n",
    "                j: 1 if i == j else 1 + imtax_Fij.get(i, {}).get(j, 0) + extax_Fij.get(i, {}).get(j, 0) + tau\n",
    "                for j in (\"A\", \"B\", \"C\") if j in imtax_Fij.get(i, {})\n",
    "            }\n",
    "            for i in (\"A\", \"B\", \"C\") if i in imtax_Fij\n",
    "        }\n",
    "        \n",
    "        # trade costs for critical goods from A to (A, B)\n",
    "        t_Ihi = {\n",
    "            h: {\n",
    "                i: 1 if h == i else 1 + imtax_Ihi.get(h, {}).get(i, 0) + extax_Ihi.get(h, {}).get(i, 0) + tau\n",
    "                for i in (\"A\", \"B\", \"C\") if i in imtax_Ihi.get(h, {})\n",
    "            }\n",
    "            for h in (\"A\", \"B\") if h in imtax_Ihi\n",
    "        }\n",
    "        \n",
    "        # calculate price of final goods (p_Fi) = input price index (bar_P_Ii)\n",
    "        p_Fi = {i: np.sum([(p_Ih[h] * t_Ihi[h][i]) ** (1 - sigma) for h in (\"A\", \"B\")]) ** (1 / (1 - sigma)) for i in (\"A\", \"B\")}\n",
    "        \n",
    "        # calculate price index for final goods consumed in country j\n",
    "        bar_P_Fj = {j: np.sum([(p_Fi[i] * t_Fij[i][j]) ** (1 - sigma) for i in (\"A\", \"B\")]) ** (1 / (1 - sigma)) for j in (\"A\", \"B\", \"C\")}\n",
    "        \n",
    "        # expected demand for final goods\n",
    "        expected_x_Fij = {\n",
    "            i: {j: (p_Fi[i] * t_Fij[i][j]) ** (-sigma) * bar_P_Fj[j] ** ((sigma * (1 - theta) - 1) / (1 - theta)) for j in (\"A\", \"B\", \"C\")}\n",
    "            for i in (\"A\", \"B\")\n",
    "        }\n",
    "        \n",
    "        # expected demand for inputs\n",
    "        expected_X_Ihi = {\n",
    "            h: {\n",
    "                i: (p_Ih[h] * t_Ihi[h][i]) ** -sigma\n",
    "                * sum(\n",
    "                    t_Fij[i][j] ** -sigma\n",
    "                    * bar_P_Fj[j] ** ((sigma * (1 - theta) - 1) / (1 - theta))\n",
    "                    for j in (\"A\", \"B\", \"C\")\n",
    "                )\n",
    "                for i in (\"A\", \"B\")\n",
    "            }\n",
    "            for h in (\"A\", \"B\")\n",
    "        }\n",
    "        \n",
    "        # n_h (number of entrants) for each h\n",
    "        n_h = {\n",
    "            h: sum(expected_X_Ihi[h][i] for i in (\"A\", \"B\"))\n",
    "            / ((sigma - 1) * (1 - e_h[h]) * kappa)\n",
    "            * ((1 / expected_phi_h[h]) - z_h[h])\n",
    "            for h in (\"A\", \"B\")\n",
    "        }\n",
    "        \n",
    "        # expected survivors for each h\n",
    "        ns_h = {\n",
    "            h: n_h[h] * expected_phi_h[h] for h in (\"A\", \"B\")\n",
    "            for h in (\"A\", \"B\")\n",
    "        }\n",
    "        \n",
    "        # monte carlo setup\n",
    "        iteration = 0\n",
    "        results = []\n",
    "        cvar_results = []\n",
    "        \n",
    "        # run the loop until convergence or max iterations\n",
    "        while iteration < max_iterations:\n",
    "            iteration += 1   \n",
    "            \n",
    "            # generate risk factors\n",
    "            D_h = {\n",
    "                h: 1 - beta.rvs(alpha_c[h], beta_c[h], size = num_simulations)\n",
    "                for h in (\"A\", \"B\")\n",
    "            }\n",
    "            fail_all_h = {\n",
    "                h: np.random.rand(num_simulations) < D_h[h]\n",
    "                for h in (\"A\", \"B\")\n",
    "            }\n",
    "            phi_h = {\n",
    "                h: np.where(fail_all_h[h], 0, beta.rvs(alpha_i, beta_i, size = num_simulations))\n",
    "                for h in (\"A\", \"B\")\n",
    "            }\n",
    "            \n",
    "            # compute rho_i directly for all samples\n",
    "            rho_i = {\n",
    "                i: (np.sum(\n",
    "                    [\n",
    "                        (\n",
    "                            ((phi_h[h] / expected_phi_h[h]) ** ((sigma - 1) / sigma))\n",
    "                            * (\n",
    "                                (1 / expected_phi_h[h] - z_h[h]) ** (1 - sigma)\n",
    "                            )\n",
    "                            * (t_Ihi[h][i] ** (1 - sigma))\n",
    "                        )\n",
    "                        for h in (\"A\", \"B\")\n",
    "                    ],\n",
    "                    axis = 0,\n",
    "                )\n",
    "                / np.sum(\n",
    "                    [\n",
    "                        (\n",
    "                            (1 / expected_phi_h[h] - z_h[h]) ** (1 - sigma)\n",
    "                            * (t_Ihi[h][i] ** (1 - sigma))\n",
    "                        )\n",
    "                        for h in [\"A\", \"B\"]\n",
    "                    ],\n",
    "                    axis = 0,\n",
    "                )) ** (sigma / (sigma - 1))\n",
    "                for i in [\"A\", \"B\"]\n",
    "            }\n",
    "\n",
    "            # tariff revenue\n",
    "            tariff_revenue = {\n",
    "                j: sum(\n",
    "                    imtax_Fij.get(i, {}).get(j, 0) * rho_i.get(i, {}) * expected_x_Fij.get(i, {}).get(j, 0)\n",
    "                    for i in (\"A\", \"B\") if i != j\n",
    "                ) + (sum(\n",
    "                    imtax_Ihi.get(i, {}).get(j, 0) * phi_h[i] / expected_phi_h[i] * expected_X_Ihi.get(i, {}).get(j, 0)\n",
    "                    for i in (\"A\", \"B\") if i != j\n",
    "                ) if j in (\"A\", \"B\") else 0)\n",
    "                + (sum(\n",
    "                    extax_Fij.get(j, {}).get(i, 0) * rho_i.get(j, {}) * expected_x_Fij.get(j, {}).get(i, 0)\n",
    "                    for i in (\"A\", \"B\") if j != i\n",
    "                ) if j in (\"A\", \"B\") else 0)\n",
    "                + (sum(\n",
    "                    extax_Ihi.get(j, {}).get(i, 0) * phi_h[j] / expected_phi_h[j] * expected_X_Ihi.get(j, {}).get(i, 0)\n",
    "                    for i in (\"A\", \"B\") if j != i\n",
    "                ) if j in (\"A\", \"B\") else 0)\n",
    "                for j in (\"A\", \"B\", \"C\")\n",
    "            }\n",
    "            \n",
    "            # production/entry subsidy cost\n",
    "            subsidy_cost = {\n",
    "                h: phi_h[h] * n_h[h] * e_h[h] + z_h[h] * sum(\n",
    "                    phi_h[h] / expected_phi_h[h] * expected_X_Ihi[h][i] for i in (\"A\", \"B\")\n",
    "                )\n",
    "                for h in (\"A\", \"B\")\n",
    "            }\n",
    "            \n",
    "            # outside good consumption\n",
    "            x_0j = {\n",
    "                j: 1\n",
    "                + tariff_revenue.get(j, 0)\n",
    "                - subsidy_cost.get(j, 0)\n",
    "                - bar_P_Fj.get(j, 0) ** (-theta / (1 - theta))\n",
    "                for j in (\"A\", \"B\", \"C\")\n",
    "            }\n",
    "            \n",
    "            # compute utility U_j\n",
    "            sum_term = {\n",
    "                j: \n",
    "                (((rho_i[\"A\"] * expected_x_Fij[\"A\"][j]) ** ((sigma - 1) / sigma) + \n",
    "                  (rho_i[\"B\"] * expected_x_Fij[\"B\"][j]) ** ((sigma - 1) / sigma)))\n",
    "                for j in (\"A\", \"B\", \"C\")\n",
    "            }\n",
    "            \n",
    "            U_j = {\n",
    "                j: x_0j.get(j, 0) +\n",
    "                   (1 / theta) * (sum_term.get(j, 0) ** (theta * sigma / (sigma - 1)))\n",
    "                for j in (\"A\", \"B\")\n",
    "            }\n",
    "            \n",
    "            # Calculate VaR as a dictionary\n",
    "            var_threshold = {\n",
    "                j: np.percentile(U_j[j], (1 - cvar_alpha) * 100) for j in U_j.keys()\n",
    "            }\n",
    "            \n",
    "            # Calculate CVaR as a dictionary\n",
    "            cvar = {\n",
    "                j: np.mean([u for u in U_j[j] if u <= var_threshold[j]]) for j in U_j.keys()\n",
    "            }\n",
    "            \n",
    "            # Append results\n",
    "            cvar_results.append(cvar)\n",
    "            results.append({j: np.mean(U_j[j]) for j in U_j.keys()})\n",
    "        \n",
    "            # Extract utility and CVaR results for country \"A\"\n",
    "            cvar_results_A = [cvar[\"A\"] for cvar in cvar_results]\n",
    "            results_A = [result[\"A\"] for result in results]\n",
    "            \n",
    "            # calculate standard errors for country \"A\"\n",
    "            cvar_sem_A = (\n",
    "                np.std(cvar_results_A, ddof=1) / np.sqrt(len(cvar_results_A))\n",
    "                if len(cvar_results_A) > 1\n",
    "                else 0  # use 0 if variance can't be computed\n",
    "            )\n",
    "            mean_sem_A = (\n",
    "                np.std(results_A, ddof=1) / np.sqrt(len(results_A))\n",
    "                if len(results_A) > 1\n",
    "                else 0\n",
    "            )\n",
    "            \n",
    "            # calculate confidence interval widths for country A\n",
    "            mean_ci_width_A = 2 * z_alpha * mean_sem_A\n",
    "            cvar_ci_width_A = 2 * z_alpha * cvar_sem_A\n",
    "            \n",
    "            # check convergence for country A\n",
    "            mean_converged_A = (\n",
    "                len(results_A) > min_iterations\n",
    "                and (mean_ci_width_A / np.abs(np.mean(results_A))) < tolerance\n",
    "            )\n",
    "            cvar_converged_A = (\n",
    "                len(cvar_results_A) > min_iterations\n",
    "                and (cvar_ci_width_A / np.abs(np.mean(cvar_results_A))) < tolerance\n",
    "            )\n",
    "            \n",
    "            if mean_converged_A and cvar_converged_A:\n",
    "                # print(f\"Converged after {iteration} iterations.\")\n",
    "                break\n",
    "        else:\n",
    "            print(\"Reached maximum iterations without convergence.\")\n",
    "\n",
    "        # after the monte carlo loop\n",
    "        final_cvar = {k: np.mean([c[k] for c in cvar_results]) for k in cvar.keys()}\n",
    "        final_utility = {k: np.mean([r[k] for r in results]) for k in results[0].keys()}\n",
    "\n",
    "        # log progress\n",
    "        current_iteration += 1\n",
    "        log_progress(current_iteration, total_iterations, interval = 10)\n",
    "        \n",
    "        # append to ex_loop_results\n",
    "        ex_loop_results.append({\n",
    "            \"extax_AB\": extax_AB,\n",
    "            \"extax_BA\": extax_BA,\n",
    "            \"utility_A\": final_utility[\"A\"],\n",
    "            \"utility_B\": final_utility[\"B\"],\n",
    "            \"cvar_A\": final_cvar[\"A\"],\n",
    "            \"cvar_B\": final_cvar[\"B\"],\n",
    "            \"symmetric\": 1 if extax_AB == extax_BA else 0\n",
    "        })\n",
    "\n",
    "# save csv\n",
    "results_df = pd.DataFrame(ex_loop_results)\n",
    "results_df.to_csv(\"output/export_tax_loop_asymmetric_risk.csv\", index = False)\n",
    "\n",
    "print(\"Results saved as export_tax_loop_asymmetric_risk.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "24bc910c-d66f-4af0-9a46-ca08abb74992",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved as prod_subsidy_loop_low_risk.csv\n"
     ]
    }
   ],
   "source": [
    "# production subsidy loop\n",
    "# run the top two cells first to retrieve parameters\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# use a higher number here - variance gets big\n",
    "max_iterations = 3000\n",
    "\n",
    "sub_sequence = np.arange(0, 0.90, 0.05)\n",
    "sub_loop_results = []\n",
    "\n",
    "for i in sub_sequence:\n",
    "\n",
    "    sub_A = i\n",
    "    \n",
    "    for j in sub_sequence:\n",
    "\n",
    "        no_convergence = 0\n",
    "        \n",
    "        sub_B = j\n",
    "\n",
    "        z_h = {\"A\": sub_A, \"B\": sub_B}\n",
    "        \n",
    "        # trade costs for critical goods from A to (A, B)\n",
    "        t_Fij = {\n",
    "            i: {\n",
    "                j: 1 if i == j else 1 + imtax_Fij.get(i, {}).get(j, 0) + extax_Fij.get(i, {}).get(j, 0) + tau\n",
    "                for j in (\"A\", \"B\", \"C\") if j in imtax_Fij.get(i, {})\n",
    "            }\n",
    "            for i in (\"A\", \"B\", \"C\") if i in imtax_Fij\n",
    "        }\n",
    "        \n",
    "        # trade costs for critical goods from A to (A, B)\n",
    "        t_Ihi = {\n",
    "            h: {\n",
    "                i: 1 if h == i else 1 + imtax_Ihi.get(h, {}).get(i, 0) + extax_Ihi.get(h, {}).get(i, 0) + tau\n",
    "                for i in (\"A\", \"B\", \"C\") if i in imtax_Ihi.get(h, {})\n",
    "            }\n",
    "            for h in (\"A\", \"B\") if h in imtax_Ihi\n",
    "        }\n",
    "\n",
    "        # calculate input prices\n",
    "        p_Ih = {\n",
    "            \"A\": (sigma / (sigma - 1)) * (1 / expected_phi_h[\"A\"] - z_h[\"A\"]),\n",
    "            \"B\": (sigma / (sigma - 1)) * (1 / expected_phi_h[\"B\"] - z_h[\"B\"]),\n",
    "        }\n",
    "        \n",
    "        # calculate price of final goods (p_Fi) = input price index (bar_P_Ii)\n",
    "        p_Fi = {i: np.sum([(p_Ih[h] * t_Ihi[h][i]) ** (1 - sigma) for h in (\"A\", \"B\")]) ** (1 / (1 - sigma)) for i in (\"A\", \"B\")}\n",
    "        \n",
    "        # calculate price index for final goods consumed in country j\n",
    "        bar_P_Fj = {j: np.sum([(p_Fi[i] * t_Fij[i][j]) ** (1 - sigma) for i in (\"A\", \"B\")]) ** (1 / (1 - sigma)) for j in (\"A\", \"B\", \"C\")}\n",
    "        \n",
    "        # expected demand for final goods\n",
    "        expected_x_Fij = {\n",
    "            i: {j: (p_Fi[i] * t_Fij[i][j]) ** (-sigma) * bar_P_Fj[j] ** ((sigma * (1 - theta) - 1) / (1 - theta)) for j in (\"A\", \"B\", \"C\")}\n",
    "            for i in (\"A\", \"B\")\n",
    "        }\n",
    "        \n",
    "        # expected demand for inputs\n",
    "        expected_X_Ihi = {\n",
    "            h: {\n",
    "                i: (p_Ih[h] * t_Ihi[h][i]) ** -sigma\n",
    "                * sum(\n",
    "                    t_Fij[i][j] ** -sigma\n",
    "                    * bar_P_Fj[j] ** ((sigma * (1 - theta) - 1) / (1 - theta))\n",
    "                    for j in (\"A\", \"B\", \"C\")\n",
    "                )\n",
    "                for i in (\"A\", \"B\")\n",
    "            }\n",
    "            for h in (\"A\", \"B\")\n",
    "        }\n",
    "        \n",
    "        # n_h (number of entrants) for each h\n",
    "        n_h = {\n",
    "            h: sum(expected_X_Ihi[h][i] for i in (\"A\", \"B\"))\n",
    "            / ((sigma - 1) * (1 - e_h[h]) * kappa)\n",
    "            * ((1 / expected_phi_h[h]) - z_h[h])\n",
    "            for h in (\"A\", \"B\")\n",
    "        }\n",
    "        \n",
    "        # expected survivors for each h\n",
    "        ns_h = {\n",
    "            h: n_h[h] * expected_phi_h[h] for h in (\"A\", \"B\")\n",
    "            for h in (\"A\", \"B\")\n",
    "        }\n",
    "        \n",
    "        # monte carlo setup\n",
    "        iteration = 0\n",
    "        results = []\n",
    "        cvar_results = []\n",
    "        \n",
    "        # run the loop until convergence or max iterations\n",
    "        while iteration < max_iterations:\n",
    "            iteration += 1   \n",
    "            \n",
    "            # generate risk factors\n",
    "            D_h = {\n",
    "                h: 1 - beta.rvs(alpha_c[h], beta_c[h], size = num_simulations)\n",
    "                for h in (\"A\", \"B\")\n",
    "            }\n",
    "            fail_all_h = {\n",
    "                h: np.random.rand(num_simulations) < D_h[h]\n",
    "                for h in (\"A\", \"B\")\n",
    "            }\n",
    "            phi_h = {\n",
    "                h: np.where(fail_all_h[h], 0, beta.rvs(alpha_i, beta_i, size = num_simulations))\n",
    "                for h in (\"A\", \"B\")\n",
    "            }\n",
    "            \n",
    "            # compute rho_i directly for all samples\n",
    "            rho_i = {\n",
    "                i: (np.sum(\n",
    "                    [\n",
    "                        (\n",
    "                            ((phi_h[h] / expected_phi_h[h]) ** ((sigma - 1) / sigma))\n",
    "                            * (\n",
    "                                (1 / expected_phi_h[h] - z_h[h]) ** (1 - sigma)\n",
    "                            )\n",
    "                            * (t_Ihi[h][i] ** (1 - sigma))\n",
    "                        )\n",
    "                        for h in (\"A\", \"B\")\n",
    "                    ],\n",
    "                    axis = 0,\n",
    "                )\n",
    "                / np.sum(\n",
    "                    [\n",
    "                        (\n",
    "                            (1 / expected_phi_h[h] - z_h[h]) ** (1 - sigma)\n",
    "                            * (t_Ihi[h][i] ** (1 - sigma))\n",
    "                        )\n",
    "                        for h in [\"A\", \"B\"]\n",
    "                    ],\n",
    "                    axis = 0,\n",
    "                )) ** (sigma / (sigma - 1))\n",
    "                for i in [\"A\", \"B\"]\n",
    "            }\n",
    "\n",
    "            # tariff revenue\n",
    "            tariff_revenue = {\n",
    "                j: sum(\n",
    "                    imtax_Fij.get(i, {}).get(j, 0) * rho_i.get(i, {}) * expected_x_Fij.get(i, {}).get(j, 0)\n",
    "                    for i in (\"A\", \"B\") if i != j\n",
    "                ) + (sum(\n",
    "                    imtax_Ihi.get(i, {}).get(j, 0) * phi_h[i] / expected_phi_h[i] * expected_X_Ihi.get(i, {}).get(j, 0)\n",
    "                    for i in (\"A\", \"B\") if i != j\n",
    "                ) if j in (\"A\", \"B\") else 0)\n",
    "                + (sum(\n",
    "                    extax_Fij.get(j, {}).get(i, 0) * rho_i.get(j, {}) * expected_x_Fij.get(j, {}).get(i, 0)\n",
    "                    for i in (\"A\", \"B\") if j != i\n",
    "                ) if j in (\"A\", \"B\") else 0)\n",
    "                + (sum(\n",
    "                    extax_Ihi.get(j, {}).get(i, 0) * phi_h[j] / expected_phi_h[j] * expected_X_Ihi.get(j, {}).get(i, 0)\n",
    "                    for i in (\"A\", \"B\") if j != i\n",
    "                ) if j in (\"A\", \"B\") else 0)\n",
    "                for j in (\"A\", \"B\", \"C\")\n",
    "            }\n",
    "            \n",
    "            # production/entry subsidy cost\n",
    "            subsidy_cost = {\n",
    "                h: phi_h[h] * n_h[h] * e_h[h] + z_h[h] * sum(\n",
    "                    phi_h[h] / expected_phi_h[h] * expected_X_Ihi[h][i] for i in (\"A\", \"B\")\n",
    "                )\n",
    "                for h in (\"A\", \"B\")\n",
    "            }\n",
    "            \n",
    "            # outside good consumption\n",
    "            x_0j = {\n",
    "                j: 1\n",
    "                + tariff_revenue.get(j, 0)\n",
    "                - subsidy_cost.get(j, 0)\n",
    "                - bar_P_Fj.get(j, 0) ** (-theta / (1 - theta))\n",
    "                for j in (\"A\", \"B\", \"C\")\n",
    "            }\n",
    "            \n",
    "            # compute utility U_j\n",
    "            sum_term = {\n",
    "                j: \n",
    "                (((rho_i[\"A\"] * expected_x_Fij[\"A\"][j]) ** ((sigma - 1) / sigma) + \n",
    "                  (rho_i[\"B\"] * expected_x_Fij[\"B\"][j]) ** ((sigma - 1) / sigma)))\n",
    "                for j in (\"A\", \"B\", \"C\")\n",
    "            }\n",
    "            \n",
    "            U_j = {\n",
    "                j: x_0j.get(j, 0) +\n",
    "                   (1 / theta) * (sum_term.get(j, 0) ** (theta * sigma / (sigma - 1)))\n",
    "                for j in (\"A\", \"B\")\n",
    "            }\n",
    "            \n",
    "            # Calculate VaR as a dictionary\n",
    "            var_threshold = {\n",
    "                j: np.percentile(U_j[j], (1 - cvar_alpha) * 100) for j in U_j.keys()\n",
    "            }\n",
    "            \n",
    "            # Calculate CVaR as a dictionary\n",
    "            cvar = {\n",
    "                j: np.mean([u for u in U_j[j] if u <= var_threshold[j]]) for j in U_j.keys()\n",
    "            }\n",
    "            \n",
    "            # Append results\n",
    "            cvar_results.append(cvar)\n",
    "            results.append({j: np.mean(U_j[j]) for j in U_j.keys()})\n",
    "        \n",
    "            # Extract utility and CVaR results for country \"A\"\n",
    "            cvar_results_A = [cvar[\"A\"] for cvar in cvar_results]\n",
    "            results_A = [result[\"A\"] for result in results]\n",
    "            \n",
    "            # calculate standard errors for country \"A\"\n",
    "            cvar_sem_A = (\n",
    "                np.std(cvar_results_A, ddof=1) / np.sqrt(len(cvar_results_A))\n",
    "                if len(cvar_results_A) > 1\n",
    "                else 0  # use 0 if variance can't be computed\n",
    "            )\n",
    "            mean_sem_A = (\n",
    "                np.std(results_A, ddof=1) / np.sqrt(len(results_A))\n",
    "                if len(results_A) > 1\n",
    "                else 0\n",
    "            )\n",
    "            \n",
    "            # calculate confidence interval widths for country A\n",
    "            mean_ci_width_A = 2 * z_alpha * mean_sem_A\n",
    "            cvar_ci_width_A = 2 * z_alpha * cvar_sem_A\n",
    "            \n",
    "            # check convergence for country A\n",
    "            mean_converged_A = (\n",
    "                len(results_A) > min_iterations\n",
    "                and (mean_ci_width_A / np.abs(np.mean(results_A))) < tolerance\n",
    "            )\n",
    "            cvar_converged_A = (\n",
    "                len(cvar_results_A) > min_iterations\n",
    "                and (cvar_ci_width_A / np.abs(np.mean(cvar_results_A))) < tolerance\n",
    "            )\n",
    "            \n",
    "            if mean_converged_A and cvar_converged_A:\n",
    "                # print(f\"Converged after {iteration} iterations.\")\n",
    "                break\n",
    "        else:\n",
    "            print(\"Reached maximum iterations without convergence.\")\n",
    "            no_convergence = 1\n",
    "\n",
    "        # after the monte carlo loop\n",
    "        final_cvar = {k: np.mean([c[k] for c in cvar_results]) for k in cvar.keys()}\n",
    "        final_utility = {k: np.mean([r[k] for r in results]) for k in results[0].keys()}\n",
    "        \n",
    "        # append to ex_loop_results\n",
    "        sub_loop_results.append({\n",
    "            \"sub_A\": sub_A,\n",
    "            \"sub_B\": sub_B,\n",
    "            \"utility_A\": final_utility[\"A\"],\n",
    "            \"utility_B\": final_utility[\"B\"],\n",
    "            \"cvar_A\": final_cvar[\"A\"],\n",
    "            \"cvar_B\": final_cvar[\"B\"],\n",
    "            \"symmetric\": 1 if sub_A == sub_B else 0,\n",
    "            \"no_convergence\": no_convergence,\n",
    "        })\n",
    "\n",
    "# save csv\n",
    "results_df = pd.DataFrame(sub_loop_results)\n",
    "results_df.to_csv(\"output/prod_subsidy_loop_low_risk.csv\", index=False)\n",
    "\n",
    "print(\"Results saved as prod_subsidy_loop_low_risk.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
